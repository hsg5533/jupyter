{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13장. 텍스트마이닝_감성분석과 토픽분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - pandas 버전이 1.1.4 이상인지 확인하고, 아니라면 upgrade 하기. (pyLDA 에러 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ★★ 11장 결정트리분석에서 Pandas를 하위버전으로 설치하였으므로,  최신버전으로 업그레이드 설치한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Anaconda Prompt 를 [관리자권한으로 실행] 한 후에, 명령어 입력:  pip  install  --upgrade  pandas \n",
    "###    -> 업그레이드 설치를 적용하기 위해서, Jupyter Notobook을 종료했다가 다시 실행하기 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글 UnicoedEncodingError를 방지하기 위해 기본 인코딩을 \"utf-8\"로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경고메시지 표시 안하게 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1부. 감성 분류 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 깃허브에서 데이터 파일 다운로드 : https://github.com/e9t/nsmc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비 및 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) 훈련용 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 훈련용 데이터 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_train_df = pd.read_csv('data/ratings_train.txt', encoding='utf8', sep='\\t', engine='python')\n",
    "nsmc_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 데이터의 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsmc_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 'document'칼럼이 Null인 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_train_df = nsmc_train_df[nsmc_train_df['document'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsmc_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 타겟 컬럼 label 확인 (0: 부정감성,   1: 긍정감성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsmc_train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 한글 이외의 문자는 공백으로 변환 (정규표현식 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsmc_train_df['document'] = nsmc_train_df['document'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "nsmc_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) 평가용 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 평가용 데이터 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsmc_test_df = pd.read_csv('data/ratings_test.txt', encoding='utf8', sep='\\t', engine='python')\n",
    "nsmc_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 데이터의 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsmc_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 'document'칼럼이 Null인 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_test_df = nsmc_test_df[nsmc_test_df['document'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 타겟 컬럼 label 확인 (0: 부정감성, 1: 긍정감성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nsmc_test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 한글 이외의 문자는 공백으로 변환 (정규표현식 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_test_df['document'] = nsmc_test_df['document'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \"\", x))\n",
    "nsmc_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 분석 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) 피처 벡터화 : TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 형태소를 분석하여 토큰화 : 한글 형태소 엔진으로 Okt 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okt_tokenizer(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) TF-IDF 기반 피처 벡터 생성 : 실행시간 10분 정도 걸립니다 ☺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer = okt_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf.fit(nsmc_train_df['document'])\n",
    "nsmc_train_tfidf = tfidf.transform(nsmc_train_df['document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) 감성 분류 모델 구축 : 로지스틱 회귀를 이용한 이진 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Sentiment Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 로지스틱 회귀 기반 분석모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "SA_lr = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_lr.fit(nsmc_train_tfidf, nsmc_train_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 로지스틱 회귀의  best 하이퍼파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C': [1, 3, 3.5, 4, 4.5, 5]}\n",
    "SA_lr_grid_cv = GridSearchCV(SA_lr, param_grid=params, cv=3, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 최적 분석 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_lr_grid_cv.fit(nsmc_train_tfidf, nsmc_train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SA_lr_grid_cv.best_params_, round(SA_lr_grid_cv.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 파라미터의 best 모델 저장\n",
    "SA_lr_best = SA_lr_grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 분석 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) 평가용 데이터를 이용하여 감성 분석 모델 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가용 데이터의 피처 벡터화 : 실행시간 6분 정도 걸립니다 ☺\n",
    "nsmc_test_tfidf = tfidf.transform(nsmc_test_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = SA_lr_best.predict(nsmc_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('감성 분석 정확도 : ', round(accuracy_score(nsmc_test_df['label'], test_predict), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) 새로운 텍스트에 대한 감성 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = input('감성 분석할 문장입력 >> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) 입력 텍스트에 대한 전처리 수행\n",
    "st = re.compile(r'[ㄱ-ㅣ가-힣]+').findall(st)\n",
    "print(st)\n",
    "st = [\" \".join(st)]\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 입력 텍스트의 피처 벡터화\n",
    "st_tfidf = tfidf.transform(st)\n",
    "\n",
    "# 2) 최적 감성분석 모델에 적용하여 감성 분석 평가\n",
    "st_predict = SA_lr_best.predict(st_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 예측 값 출력하기\n",
    "if(st_predict== 0):\n",
    "    print(st , \"->> 부정 감성\")\n",
    "else :\n",
    "    print(st , \"->> 긍정 감성\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2부. 감성 분석 수행 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 감성 분석할 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 4장에서 학습한 네이버 API를 이용한 크롤링 프로그램을 이용하여, 네이버 뉴스를 크롤링하여 텍스트 데이터를 수집한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비 및 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = '코로나_naver_news'\n",
    "\n",
    "with open('data/'+file_name+'.json', encoding='utf8') as j_f:\n",
    "    data = json.load(j_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 분석할 컬럼을 추출하여 데이터 프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title =[]\n",
    "data_description = []\n",
    "\n",
    "for item in data:\n",
    "    data_title.append(item['title'])\n",
    "    data_description.append(item['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({'title':data_title, 'description':data_description})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 한글 이외 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df['title'] = data_df['title'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "data_df['description'] = data_df['description'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "\n",
    "data_df.head()  #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 감성 분석 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) 'title'에 대한 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 분석할 데이터의 피처 벡터화 ---<< title >> 분석\n",
    "data_title_tfidf = tfidf.transform(data_df['title'])\n",
    "\n",
    "# 2) 최적 파라미터 학습모델에 적용하여 감성 분석\n",
    "data_title_predict = SA_lr_best.predict(data_title_tfidf)\n",
    "\n",
    "# 3) 감성 분석 결과값을 데이터 프레임에 저장\n",
    "data_df['title_label'] = data_title_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) 'description' 에 대한 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 분석할 데이터의 피처 벡터화 ---<< description >> 분석\n",
    "data_description_tfidf = tfidf.transform(data_df['description'])\n",
    "\n",
    "# 2) 최적 파라미터 학습모델에 적용하여 감성 분석\n",
    "data_description_predict = SA_lr_best.predict(data_description_tfidf)\n",
    "\n",
    "# 3) 감성 분석 결과값을 데이터 프레임에 저장\n",
    "data_df['description_label'] = data_description_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3)  분석 결과가 추가된 데이터프레임을 CSV 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일로 저장 ---------------------------------------------\n",
    "data_df.to_csv('./13장_data/'+file_name+'.csv', encoding='euc-kr') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 감성 분석 결과 확인 및 시각화 - 0: 부정감성,   1: 긍정감성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) 감성 분석 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df['title_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df['description_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) 결과 저장 : 긍정과 부정을 분리하여 CSV 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['title','title_label','description','description_label']\n",
    "NEG_data_df = pd.DataFrame(columns=columns_name)\n",
    "POS_data_df = pd.DataFrame(columns=columns_name)\n",
    "\n",
    "for i, data in data_df.iterrows(): \n",
    "    title = data[\"title\"] \n",
    "    description = data[\"description\"] \n",
    "    t_label = data[\"title_label\"] \n",
    "    d_label = data[\"description_label\"] \n",
    "    \n",
    "    if d_label == 0: # 부정 감성 샘플만 추출\n",
    "        NEG_data_df = NEG_data_df.append(pd.DataFrame([[title, t_label, description, d_label]],columns=columns_name),ignore_index=True)\n",
    "    else : # 긍정 감성 샘플만 추출\n",
    "        POS_data_df = POS_data_df.append(pd.DataFrame([[title, t_label, description, d_label]],columns=columns_name),ignore_index=True)\n",
    "     \n",
    "# 파일에 저장.\n",
    "NEG_data_df.to_csv('data/'+file_name+'_NES.csv', encoding='euc-kr') \n",
    "POS_data_df.to_csv('data/'+file_name+'_POS.csv', encoding='euc-kr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(NEG_data_df), len(POS_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3)  감성 분석 결과 시각화 : 바 차트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 명사만 추출하여 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 긍정 감성의 데이터에서 명사만 추출하여 정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_description = POS_data_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_description_noun_tk = []\n",
    "\n",
    "for d in POS_description:\n",
    "    POS_description_noun_tk.append(okt.nouns(d)) #형태소가 명사인 것만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(POS_description_noun_tk)  #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_description_noun_join = []\n",
    "\n",
    "for d in POS_description_noun_tk:\n",
    "    d2 = [w for w in d if len(w) > 1] #길이가 1인 토큰은 제외\n",
    "    POS_description_noun_join.append(\" \".join(d2)) # 토큰을 연결(join)하여 리스트 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(POS_description_noun_join)  #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 부정 감성의 데이터에서 명사만 추출하여 정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_description = NEG_data_df['description']\n",
    "\n",
    "NEG_description_noun_tk = []\n",
    "NEG_description_noun_join = []\n",
    "\n",
    "for d in NEG_description:\n",
    "    NEG_description_noun_tk.append(okt.nouns(d)) #형태소가 명사인 것만 추출\n",
    "    \n",
    "for d in NEG_description_noun_tk:\n",
    "    d2 = [w for w in d if len(w) > 1]  #길이가 1인 토큰은 제외\n",
    "    NEG_description_noun_join.append(\" \".join(d2)) # 토큰을 연결(join)하여 리스트 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(NEG_description_noun_join)  #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) dtm 구성 : 단어 벡터 값을 내림차순으로 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 긍정 감성 데이터에 대한 dtm 구성, dtm을 이용하여 단어사전 구성 후 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_tfidf = TfidfVectorizer(tokenizer = okt_tokenizer, min_df=2 )\n",
    "POS_dtm = POS_tfidf.fit_transform(POS_description_noun_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_vocab = dict() \n",
    "\n",
    "for idx, word in enumerate(POS_tfidf.get_feature_names()):\n",
    "    POS_vocab[word] = POS_dtm.getcol(idx).sum()\n",
    "    \n",
    "POS_words = sorted(POS_vocab.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "POS_words  #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 부정 감성 데이터의 dtm 구성, dtm을 이용하여 단어사전 구성 후 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_tfidf = TfidfVectorizer(tokenizer = okt_tokenizer, min_df=2 )\n",
    "NEG_dtm = NEG_tfidf.fit_transform(NEG_description_noun_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_vocab = dict() \n",
    "\n",
    "for idx, word in enumerate(NEG_tfidf.get_feature_names()):\n",
    "    NEG_vocab[word] = NEG_dtm.getcol(idx).sum()\n",
    "    \n",
    "NEG_words = sorted(NEG_vocab.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NEG_words   #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 단어사전의 상위 단어로 바 차트 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fm.get_fontconfig_fonts()\n",
    "font_location = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_name = fm.FontProperties(fname=font_location).get_name()\n",
    "matplotlib.rc('font', family=font_name)\n",
    "\n",
    "max = 15  #바 차트에 나타낼 단어의 수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(max), [i[1] for i in POS_words[:max]], color=\"blue\")\n",
    "plt.title(\"긍정 뉴스의 단어 상위 %d개\" %max, fontsize=15)\n",
    "plt.xlabel(\"단어\", fontsize=12)\n",
    "plt.ylabel(\"TF-IDF의 합\", fontsize=12)\n",
    "plt.xticks(range(max), [i[0] for i in POS_words[:max]], rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(max), [i[1] for i in NEG_words[:max]], color=\"red\")\n",
    "plt.title(\"부정 뉴스의 단어 상위 %d개\" %max, fontsize=15)\n",
    "plt.xlabel(\"단어\", fontsize=12)\n",
    "plt.ylabel(\"TF-IDF의 합\", fontsize=12)\n",
    "plt.xticks(range(max), [i[0] for i in NEG_words[:max]], rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3부. 토픽모델링 : LDA 기반 토픽 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) 'description' 컬럼 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = data_df['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) 형태소 토큰화 : 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_noun_tk = []\n",
    "\n",
    "for d in description:\n",
    "    description_noun_tk.append(okt.nouns(d)) #형태소가 명사인 것만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_noun_tk2 = []\n",
    "\n",
    "for d in description_noun_tk:\n",
    "    item = [i for i in d if len(i) > 1]  #토큰의 길이가 1보다 큰 것만 추출\n",
    "    description_noun_tk2.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description_noun_tk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LDA 토픽 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) LDA 모델의 입력 벡터 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초 한번만 설치\n",
    "!pip install gensim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(description_noun_tk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary[1])  #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 단어와 출현빈도(count)의 코퍼스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(word) for word in description_noun_tk2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus) #작업 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) LDA 모델 생성 및 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4  #토픽의 개수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamulticore.LdaMulticore(corpus, iterations = 12, num_topics = k, id2word = dictionary, passes = 1, workers = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LDA 토픽 분석 결과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) 토픽 분석 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda_model.print_topics(num_topics = k, num_words = 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) 토픽 분석 결과 시각화 : pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #최초 한번만 설치\n",
    "!pip install pyLDAvis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda_vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(lda_vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
