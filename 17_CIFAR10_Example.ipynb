{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hQYJd6kNRT1B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NHqiSBh5wwPW"
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=20,\n",
    "                         shear_range=0.2,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQRg7DpRRdwK",
    "outputId": "0080e90b-b889-41d7-d6e8-35f4f2826e73"
   },
   "outputs": [],
   "source": [
    "# CIFAR-10 데이터셋을 읽고 신경망에 입력할 형태로 변환\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVH0jmvdCyDD",
    "outputId": "98c6189d-e2b8-4f1b-9aa8-89cf66f92e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000\n",
      "(75000, 32, 32, 3) (75000, 1)\n",
      "(75000, 32, 32, 3) (75000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 보강할 학습데이터 이미지 생성\n",
    "\n",
    "augment_ratio = 1.5   # 전체 데이터의 150%\n",
    "augment_size = int(augment_ratio * x_train.shape[0])\n",
    "\n",
    "print(augment_size)\n",
    "\n",
    "# 전체 x_train 개수의 150% 비율만큼\n",
    "randidx = np.random.randint(x_train.shape[0], size=augment_size)\n",
    "\n",
    "# 임의로 선택된 데이터는 원본데이터를 참조하기 때문에\n",
    "# 원본데이터에 영향을 줄수 있음. 그래서 copy() 함수를 통해 안전하게 복사본 만듬\n",
    "x_augmented = x_train[randidx].copy()  \n",
    "y_augmented = y_train[randidx].copy()\n",
    "\n",
    "print(x_augmented.shape, y_augmented.shape)\n",
    "\n",
    "#  이미지 보강 실행\n",
    "x_augmented, y_augmented = gen.flow(x_augmented, y_augmented, \n",
    "                                    batch_size=augment_size,\n",
    "                                    shuffle=False).next()\n",
    "\n",
    "print(x_augmented.shape, y_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdEbdaoUGA8O",
    "outputId": "465c84eb-7e79-4796-cdd7-03af256ee22d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 32, 32, 3) (125000, 1)\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train 에 보강된 데이터 추가\n",
    "\n",
    "x_train = np.concatenate( (x_train, x_augmented) )\n",
    "y_train = np.concatenate( (y_train, y_augmented) )\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ElwMmCQT6Zb"
   },
   "source": [
    "relu + Adam + (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vv7pyg3gT9OB",
    "outputId": "a0dc915c-1aa3-4e65-d6ea-573721e58b03",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 402,986\n",
      "Trainable params: 402,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델 구축\n",
    "cnn=Sequential()\n",
    "cnn.add(Conv2D(32,(3,3),activation='relu', padding='same',input_shape=(32,32,3)))\n",
    "cnn.add(Conv2D(32,(3,3),activation='relu', padding='same'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu', padding='same'))\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu', padding='same'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "#cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
    "#cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#cnn.add(Dropout(0.25))\n",
    "\n",
    "#cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
    "#cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(128,activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(10,activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "JAPP-r1NT-Fn",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f5872314-d5fc-4a6e-c14b-b3d1532a9279",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 1.3742 - accuracy: 0.5091\n",
      "Epoch 1: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 226s 460ms/step - loss: 1.3742 - accuracy: 0.5091 - val_loss: 1.0523 - val_accuracy: 0.6220\n",
      "Epoch 2/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 1.2109 - accuracy: 0.5722\n",
      "Epoch 2: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 228s 467ms/step - loss: 1.2109 - accuracy: 0.5722 - val_loss: 0.9193 - val_accuracy: 0.6740\n",
      "Epoch 3/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 1.0969 - accuracy: 0.6163\n",
      "Epoch 3: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 244s 499ms/step - loss: 1.0969 - accuracy: 0.6163 - val_loss: 0.8482 - val_accuracy: 0.7041\n",
      "Epoch 4/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 1.0229 - accuracy: 0.6438\n",
      "Epoch 4: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 339s 693ms/step - loss: 1.0229 - accuracy: 0.6438 - val_loss: 0.7838 - val_accuracy: 0.7271\n",
      "Epoch 5/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.9613 - accuracy: 0.6656\n",
      "Epoch 5: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 340s 695ms/step - loss: 0.9613 - accuracy: 0.6656 - val_loss: 0.7568 - val_accuracy: 0.7321\n",
      "Epoch 6/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.9139 - accuracy: 0.6829\n",
      "Epoch 6: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 333s 681ms/step - loss: 0.9139 - accuracy: 0.6829 - val_loss: 0.6870 - val_accuracy: 0.7582\n",
      "Epoch 7/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.8719 - accuracy: 0.6982\n",
      "Epoch 7: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 307s 627ms/step - loss: 0.8719 - accuracy: 0.6982 - val_loss: 0.6786 - val_accuracy: 0.7608\n",
      "Epoch 8/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7115\n",
      "Epoch 8: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 230s 471ms/step - loss: 0.8372 - accuracy: 0.7115 - val_loss: 0.6295 - val_accuracy: 0.7817\n",
      "Epoch 9/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.8093 - accuracy: 0.7207\n",
      "Epoch 9: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 229s 469ms/step - loss: 0.8093 - accuracy: 0.7207 - val_loss: 0.6150 - val_accuracy: 0.7875\n",
      "Epoch 10/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.7878 - accuracy: 0.7299\n",
      "Epoch 10: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 220s 450ms/step - loss: 0.7878 - accuracy: 0.7299 - val_loss: 0.5876 - val_accuracy: 0.7964\n",
      "Epoch 11/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.7662 - accuracy: 0.7358\n",
      "Epoch 11: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 221s 452ms/step - loss: 0.7662 - accuracy: 0.7358 - val_loss: 0.5638 - val_accuracy: 0.8094\n",
      "Epoch 12/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.7489 - accuracy: 0.7431\n",
      "Epoch 12: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 448ms/step - loss: 0.7489 - accuracy: 0.7431 - val_loss: 0.5575 - val_accuracy: 0.8110\n",
      "Epoch 13/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.7449\n",
      "Epoch 13: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 220s 451ms/step - loss: 0.7371 - accuracy: 0.7449 - val_loss: 0.5828 - val_accuracy: 0.8018\n",
      "Epoch 14/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.7126 - accuracy: 0.7561\n",
      "Epoch 14: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 221s 451ms/step - loss: 0.7126 - accuracy: 0.7561 - val_loss: 0.5750 - val_accuracy: 0.8072\n",
      "Epoch 15/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.7030 - accuracy: 0.7594\n",
      "Epoch 15: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 449ms/step - loss: 0.7030 - accuracy: 0.7594 - val_loss: 0.5515 - val_accuracy: 0.8139\n",
      "Epoch 16/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.7640\n",
      "Epoch 16: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 448ms/step - loss: 0.6894 - accuracy: 0.7640 - val_loss: 0.5760 - val_accuracy: 0.8031\n",
      "Epoch 17/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6760 - accuracy: 0.7670\n",
      "Epoch 17: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 449ms/step - loss: 0.6760 - accuracy: 0.7670 - val_loss: 0.5684 - val_accuracy: 0.8140\n",
      "Epoch 18/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.7703\n",
      "Epoch 18: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 220s 449ms/step - loss: 0.6698 - accuracy: 0.7703 - val_loss: 0.5253 - val_accuracy: 0.8203\n",
      "Epoch 19/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.7741\n",
      "Epoch 19: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.6608 - accuracy: 0.7741 - val_loss: 0.5311 - val_accuracy: 0.8226\n",
      "Epoch 20/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.7767\n",
      "Epoch 20: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 448ms/step - loss: 0.6518 - accuracy: 0.7767 - val_loss: 0.5168 - val_accuracy: 0.8221\n",
      "Epoch 21/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.7799\n",
      "Epoch 21: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 447ms/step - loss: 0.6425 - accuracy: 0.7799 - val_loss: 0.5218 - val_accuracy: 0.8232\n",
      "Epoch 22/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7838\n",
      "Epoch 22: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.6307 - accuracy: 0.7838 - val_loss: 0.5251 - val_accuracy: 0.8222\n",
      "Epoch 23/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.7850\n",
      "Epoch 23: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 447ms/step - loss: 0.6253 - accuracy: 0.7850 - val_loss: 0.5331 - val_accuracy: 0.8200\n",
      "Epoch 24/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.7876\n",
      "Epoch 24: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.6206 - accuracy: 0.7876 - val_loss: 0.5038 - val_accuracy: 0.8263\n",
      "Epoch 25/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.7883\n",
      "Epoch 25: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 446ms/step - loss: 0.6118 - accuracy: 0.7883 - val_loss: 0.5117 - val_accuracy: 0.8312\n",
      "Epoch 26/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.7932\n",
      "Epoch 26: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 219s 448ms/step - loss: 0.6016 - accuracy: 0.7932 - val_loss: 0.4964 - val_accuracy: 0.8299\n",
      "Epoch 27/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.7935\n",
      "Epoch 27: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.6006 - accuracy: 0.7935 - val_loss: 0.5040 - val_accuracy: 0.8319\n",
      "Epoch 28/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7934\n",
      "Epoch 28: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.6003 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.8316\n",
      "Epoch 29/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.7957\n",
      "Epoch 29: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.5918 - accuracy: 0.7957 - val_loss: 0.5103 - val_accuracy: 0.8232\n",
      "Epoch 30/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.7974\n",
      "Epoch 30: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 220s 449ms/step - loss: 0.5883 - accuracy: 0.7974 - val_loss: 0.4882 - val_accuracy: 0.8346\n",
      "Epoch 31/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.7998\n",
      "Epoch 31: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 445ms/step - loss: 0.5807 - accuracy: 0.7998 - val_loss: 0.5119 - val_accuracy: 0.8296\n",
      "Epoch 32/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.8002\n",
      "Epoch 32: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 445ms/step - loss: 0.5771 - accuracy: 0.8002 - val_loss: 0.5172 - val_accuracy: 0.8267\n",
      "Epoch 33/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.8028\n",
      "Epoch 33: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 445ms/step - loss: 0.5701 - accuracy: 0.8028 - val_loss: 0.4949 - val_accuracy: 0.8372\n",
      "Epoch 34/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.8041\n",
      "Epoch 34: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 445ms/step - loss: 0.5678 - accuracy: 0.8041 - val_loss: 0.5129 - val_accuracy: 0.8253\n",
      "Epoch 35/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8053\n",
      "Epoch 35: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 445ms/step - loss: 0.5671 - accuracy: 0.8053 - val_loss: 0.4740 - val_accuracy: 0.8420\n",
      "Epoch 36/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.8066\n",
      "Epoch 36: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 447ms/step - loss: 0.5607 - accuracy: 0.8066 - val_loss: 0.5050 - val_accuracy: 0.8295\n",
      "Epoch 37/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.8070\n",
      "Epoch 37: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 446ms/step - loss: 0.5618 - accuracy: 0.8070 - val_loss: 0.4913 - val_accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.8081\n",
      "Epoch 38: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 446ms/step - loss: 0.5558 - accuracy: 0.8081 - val_loss: 0.4878 - val_accuracy: 0.8398\n",
      "Epoch 39/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.8104\n",
      "Epoch 39: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 446ms/step - loss: 0.5496 - accuracy: 0.8104 - val_loss: 0.5157 - val_accuracy: 0.8344\n",
      "Epoch 40/50\n",
      "489/489 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.8102\n",
      "Epoch 40: saving model to /data\\bast.h5\n",
      "489/489 [==============================] - 218s 446ms/step - loss: 0.5516 - accuracy: 0.8102 - val_loss: 0.4772 - val_accuracy: 0.8380\n",
      "Elapsed Time =>  2:34:16.768900\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# 손실함수가 5 epochs을 진행을 검사하여 더 이상 줄어들지 않으면 종료\n",
    "# EarlyStopping(모니터링 값, 대기 epochs)\n",
    "\n",
    "early_stoping=EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "#학습 중인 모델을 자동 저장\n",
    "model_checkpoint=ModelCheckpoint(filepath=\"/data/bast.h5\",\n",
    "                                 monitor='val_loss', \n",
    "                                 save_base_only=True,\n",
    "                                 verbose=1)\n",
    "\n",
    "hist = cnn.fit(x_train, y_train, batch_size=256, epochs=50, validation_data=(x_test, y_test), \n",
    "               callbacks=[early_stoping, model_checkpoint])\n",
    "\n",
    "#hist = cnn.fit(x_train, y_train, batch_size=256, epochs=50, validation_data=(x_test, y_test))\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed Time => ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JicVo0mcT-Ju",
    "outputId": "4d5de808-3502-4183-a5ea-2464defc7b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4772 - accuracy: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47719013690948486, 0.8379999995231628]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "collapsed": true,
    "id": "S3kHYADGT-NJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "791bee1c-21a6-47a5-d11d-fa8585d42b8d",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhist\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy Trend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy Trend')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Xsvie3bUT_wS",
    "outputId": "c53b581c-9d39-474d-c746-64014f321987"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss Trend')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF_2_x_LEC_17_Example_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
